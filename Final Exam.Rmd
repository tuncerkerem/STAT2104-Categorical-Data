---
title: "Final Exam"
author: "Kerem Tuncer"
date: "4/20/2021"
output:
  word_document: default
  html_notebook: default
---

## Question 1

```{r}
rm(list = ls())
msparrownest <- read.csv("msparrownest.csv", header=T)
colnames(msparrownest) <- c("class", "wingspan")
logistic <- function(u){ exp(u) / (1 + exp(u)) }
```

```{r}
m1 <- glm(class~wingspan, data = msparrownest, family = binomial)
x <- range(msparrownest$wingspan)
x <- seq(x[1], x[2], 0.001)
preds <- predict(m1, data.frame(wingspan=x), se.fit=T)

plot(jitter(class,.2) ~ wingspan, pch=2-class, msparrownest, ylab="Pr(Nesting)", xlab="Wingspan", main="Model")
lines(x, logistic(preds$fit), col="red", lwd=2)
lines(x, logistic(preds$fit - 1.96 * preds$se.fit), lty=2,col="blue", lwd=2)
lines(x, logistic(preds$fit + 1.96 * preds$se.fit), lty=2,col="blue", lwd=2)

summary(m1)

exp(1.1644)
```

In the above plot, you can see the estimated nesting success probability versus wingspan, as well as a set of 95% confidence bands. The probability curve is denoted by the red line, whereas the blue dotted lines denote the 95% confidence bands. Likewise, the triangles represent observations of sparrows that did not nest, whereas the circles represent the observations where the sparrows successfully nested.

To begin with, you can see that the red line is going up from bottom left to top right, which indicates an increase in the wingspan tends to increase the probability that a sparrow will nest successfully. This trend is confirmed by the exponent of the coefficient for wingspan. We estimate that a one-unit increase in wingspan is associated with increased odds of remission by a factor of exp(1.1644) = 3.204.

Now, let's take a closer look at the probability curve. The curve is steeper in the middle portion of the wingspan data, which shows that a change in wingspan of one unit has a larger effect in this range (roughly speaking, between 11-14). Meanwhile, the curve is visually flatter below 11 and above 14. This shows that a change in wingspan of one unit has a smaller effect in these two ranges.

Another important thing to notice about our plot is the changing distance between the probability curve and the confidence bands. The distances between the bands and the curve will help us see if the fitted values' estimates are precise. The upper confidence band is further away from the probability curve in lower wingspans but closer to the probability curve in higher wingspans. However, the lower confidence band is closer to the probability curve in lower wingspans but further away from the probability curve in higher wingspans. Hence, they are not symmetric, which is what we want because of the logistic transformation we did. This allows us not to have any lower bound probability values that are below zero in unsuccessful nesting observations or any upper bound that is above one in successful nesting observations. In other words, our probability for higher wingspans can be considerably below our estimate, but not considerably above because probability cannot be more than one. Likewise, our probability for smaller wingspans can be considerably above our estimate, but not considerably below because probability cannot be less than zero.

## Question 2

### Part 1

```{r}
azdiabetes <- read.csv("azdiabetes.csv", header=T)
azdiabetes$diabetes <- as.factor(azdiabetes$diabetes)
diabetes.mod <- glm(diabetes ~ age + bmi + npreg + bp, data = azdiabetes, family = binomial)
summary(diabetes.mod)
```

Letting $\pi (x)$ denote the probability of having diabetes, the prediction equation will be the following.

$$log[\frac{\hat \pi (x)}{1 - \hat \pi (x)}] = -6.112557 + 0.049747age + 0.106890bmi + 0.075969npreg - 0.001186bp$$

$$\hat \pi (x) = \frac{e^{-6.112557 + 0.049747age + 0.106890bmi + 0.075969npreg - 0.001186bp}}{1 + e^{-6.112557 + 0.049747age + 0.106890bmi + 0.075969npreg - 0.001186bp}}$$


### Part 2


```{r}
#for age
0.049747 + c(-1,1) * 1.96 * 0.012324
exp(0.049747 + c(-1,1) * 1.96 * 0.012324) #wald
exp(0.049747 + c(-1,1) * 1.96 * 0.012324) ^ (40-25) 

confint(diabetes.mod)["age",] #profile likelihood
exp(confint(diabetes.mod)["age",])
exp(confint(diabetes.mod)["age",]) ^ (40-25) 
```


For age, I have calculated both the profile likelihood and wald 95% confidence intervals. As you can see from the output above, the 95% wald confidence interval for age was [0.02559196, 0.07390204] and its exponent was [1.025922, 1.076701]. The 95% profile likelihood confidence interval was [0.02594371, 0.07443341], and its exponent was [1.026283, 1.077274]. This means that we can be 95% confident that the increase in odds of having diabetes associated with a one-unit increase in age is between a factor of 1.025922 and 1.076701 (or 1.026283 and 1.077274 for the profile likelihood interval).

Given that the question specified the difference in odds of having diabetes between 40 and 25, we can use the confidence intervals we computed to find the difference. Only thing we have to do is compute the exponentiated confidence intervals to the power of 15, which is 40-25. For the wald intervals, we are 95% confident that the odds of having diabetes is higher for 40 year olds than for 25 year olds by a factor between 1.467968 and 3.029903 (or between 1.475734 and 3.054149 using profile likelihood). In other words, we are 95% confident that the ratio of odds of diabetes at age 40 to odds at age 25 is between 1.467968 and 3.029903 (or between 1.475734 and 3.054149 using profile likelihood).


```{r}
#for bmi
0.106890 + c(-1,1) * 1.96 * 0.016952
exp(0.106890 + c(-1,1) * 1.96 * 0.016952) #wald
exp(0.106890 + c(-1,1) * 1.96 * 0.016952) ^ (35-30)

confint(diabetes.mod)["bmi",] #profile likelihood
exp(confint(diabetes.mod)["bmi",])
exp(confint(diabetes.mod)["bmi",]) ^ (35-30)
```

For bmi, I have calculated both the profile likelihood and wald 95% confidence intervals. As you can see from the output above, the 95% wald confidence interval for bmi was [0.07366408, 0.14011592] and its exponent was [1.076445, 1.150407]. The 95% profile likelihood confidence interval was [0.07452232, 0.14112000], and its exponent was [1.077369, 1.151563]. This means that we can be 95% confident that the increase in odds of having diabetes associated with a one-unit increase in bmi is between a factor of 1.076445 and 1.150407 (or 1.077369 and 1.151563 for the profile likelihood interval). 

Given that the question specified the difference in odds of having diabetes between 35 and 30 bmi, we can use the confidence intervals we computed to find the difference. Only thing we have to do is compute the exponentiated confidence intervals to the power of 5, which is 35-30. For the wald intervals, we are 95% confident that the odds of having diabetes is higher for 35 bmi than for 30 bmi by a factor between 1.445305 and 2.014920 (or between 1.451520 and 2.025061 using profile likelihood). In other words, we are 95% confident that the ratio of odds of diabetes at 35 bmi to odds at 30 bmi is between 1.445305 and 2.014920 (or between 1.451520 2.025061 using profile likelihood).

Side notes:

(1) For both my analysis for bmi and age, it is important to note that I have interpreted the confidence intervals of conditional odds ratios while keeping the other variables constant (ceteris paribus).


```{r}
nrow(azdiabetes)
```

(2) As we have 532 observations, which is not a small sample size, our Wald intervals (which may underperform at smaller sample sizes) and profile likelihood intervals should both give reasonable estimations.

### Part 3

```{r}
diabetes.mod.2 <- glm(diabetes ~ age + bmi, data = azdiabetes, family = binomial)
anova(diabetes.mod.2, diabetes.mod, test = "Chisq")
```

For this question, we will run a likelihood ratio test (which will look at the change in deviances) to compare two models. The first model will be the one that contains all of the variables (age, bmi, npreg, bp). The second model will only contain variables age and bmi, because we want to exclude the variables that we want to test on. This test will not only tell us if the addition of these variables creates a better fit but it will also tell us if their coefficients are simultaneously zero. Now, let's first state our hypotheses.

$$H_0: \beta_{npreg} = \beta_{bp} = 0, \; so \; coefficients \; are \; simultaneously \; zero$$


$$H_a: \beta_{npreg} \neq 0 | \beta_{bp} \neq 0, \; so \; at \; least \; one \; of \; the \; coefficients \; is \; not \; zero   $$

We got a change in deviance of 577.20-573.13 = 4.0728. We also have degrees of freedom of 4-2 = 2. So, we end up with a p-value of 0.1305. Given that this p-value is above 0.05, we cannot reject the null hypothesis. We do not have enough evidence to conclude that the coefficients of bp and npreg are simultaneously not zero. We also do not have enough evidence to conclude that these two variables make a meaningful addition to the model simultaneously. All in all, the data we have does not prove that the beta coefficients for npreg and bp are not zero simultaneously.

## Question 3

```{r}
library(VGAM)
library(MASS)
prayer <- read.csv("prayer.csv", header=T)
summary(prayer)
```

FÄ±rst, let's take a look at our three variables. The prayer variable will be our dependent variable and it is an ordinal that ranges between 1 and 6. Given the ordinal nature, we know that the six categories are naturally ordered. The mean prayer value is at 4.326. Next, we have our two explanatory variables: female and vocab. Female is a binary variable where a 1 indicates a female and 0 indicates a male. Given that the mean of female is > 0.5, we can say that the dataset contains more female observations than male ones. Lastly, we have the vocab variable that ranges from 0 to 10, and we will treat as a numeric variable.

Given this information, the most optimal model will be to use a cumulative logit model for ordinal responses, which is also known as a ordinal logistic regression model. We need to keep in mind that this model uses a proportional odds assumption, which requires that explanatory variables have equal effect on the odds of moving to a higher category.

Let's begin by using polr() from the MASS library. We will convert prayer to a factor as it is required by polr(). Then, we will include both explanatory variables in the model without the interaction term. Now, let's compare this model to an intercept only model with a likelihood ratio test. It will be examining if all the coefficients except the intercept are equal to zero. Let's formulate our hypotheses for this test.

$$H_0: \beta_{female} = \beta_{vocab} = 0$$

$$H_a: \beta_{female} \neq 0 \; or \; \beta_{vocab} \neq 0$$

```{r}
q3.model <- polr(as.factor(prayer) ~ female + vocab, data = prayer, method = "logistic")
q3.empty <- polr(as.factor(prayer) ~ 1, data = prayer, method = "logistic")
anova(q3.model, q3.empty)
```

As you can see, likelihood ratio statistic was 54.81028 under 2 degrees of freedom. This results in a p-value of 1.253442e-12. Therefore, we can reject the null hypothesis. We have enough evidence to conclude that at least one of the coefficients is not equal to zero. So our model has a good fit to begin with.

Now, let's compare the goodness of the fit of our model to two separate models, where we would have each explanatory variable separately. Once again, we can use a likelihood ratio test to accomplish this task.


```{r}
only.female <- polr(as.factor(prayer) ~ female, data = prayer, method = "logistic")
only.vocab <- polr(as.factor(prayer) ~ vocab, data = prayer, method = "logistic")

anova(only.female, q3.model)
anova(only.vocab, q3.model)
```

When we compare our model with both variables to the model with only female variable, we get a LR statistic of 13.07695 under 1 degree of freedom, which results in a p-value of 0.0002989519. When we compare our model with both variables to the model with only vocab variable, we get a LR statistic of 43.36928 under 1 degree of freedom, which results in a p-value of 4.532474e-11. In both cases, our p-value is much below that of 0.05, so we can reject the null hypotheses that the single variable models provide good enough fit . We have enough evidence to conclude that the model with both variables provides a better fit than the two models where the variables are used alone. The drop in deviance for our two-variable model was significant enough.

Lastly, we should also try out a model with the interaction term between female and vocab. We will once again use a likelihood ratio test to compare the two models.

```{r}
q3.mod2 <- polr(as.factor(prayer) ~ female + vocab + female:vocab, data = prayer, method = "logistic")
anova(q3.model, q3.mod2)
```

The resulting likelihood ratio statistic is 5.53465 under a 1 degree of freedom, which results in a p-value of 0.01864349. Given that this p-value is below 0.05, we can reject the null hypothesis. This time, the model with the smaller residual deviance was the model with the interaction term. Therefore, we have enough evidence to conclude that the model with the interaction term provides a better fit than the model without the interaction term. The drop in deviance caused by the addition of the interaction term is significant enough.

As you can see from the above, I have used likelihood ratio test approach to compare the models. However, another option is to perform stepwise model selection by AIC. This can be done by comparing the AIC values of each model and selecting the one with the lowest one.

```{r}
AIC(q3.model)
AIC(only.vocab)
AIC(only.female)
AIC(q3.mod2)
```

As you can see from the output above, the model with the interaction term has the lowest AIC out of the four models that we tried. So, all in all, we are pretty confident that the model with the best fit is the model that has both variables (vocab and female) and their interaction term.

Before jumping into any conclusions, I also wanted to create a model that would treat the response variable of prayer as a nominal one. It is important to note that we cannot treat a nominal variable as an ordinal one, as that would violate assumptions. However, it is technically possible to ignore the ordering of categories and treat them as nominal (without violating assumptions). Hence, I decided to run a likelihood ratio test between our best proportional odds model and the multinomial model using the same formula. 

```{r}
q3.vglm <- vglm(prayer ~ female + vocab + female:vocab, data = prayer, family=propodds)
base.fit <- vglm(prayer ~ female + vocab + female:vocab, data = prayer, family=multinomial)
length(coef(base.fit))
length(coef(q3.vglm))
lrtest(q3.vglm, base.fit)
```

As you can see from the output above, our likelihood ratio statistic is 20.273 under 12 degrees of freedom, which results in a p-value of 0.06209. Given that the p-value is above 0.05, we are unable to reject the null hypothesis. It is true that the multinomial model resulted in some drop in residual deviance. However, this drop in deviance was not statistically significant. This multinomial model also requires many more parameters compared to the proportional odds model. All in all, we do not have enough evidence to conclude that the multinomial model will provide better fit. Likewise, using a multinomial model would also take a hit on the interpretability aspect, as the response variable will have to be interpreted with out assuming a natural ordering.

In conclusion, I am pretty confident about the fit of my proportional odds cumulative logit model on the data I have. Now, we are ready to interpret our model. Let's first begin by reporting the prediction equations.

```{r}
summary(q3.mod2)
```
```{r}
pnorm(abs(4.368), lower.tail = FALSE) * 2
pnorm(abs(-0.635), lower.tail = FALSE) * 2
pnorm(abs(-2.35), lower.tail = FALSE) * 2
```



In polr, the ordinal logistic regression model takes the following format, which is known as the latent variable induced form:

$$logit(P(Y \leq j )) = \alpha_{j} - \beta_1x_1 - ... - \beta_px_p$$

Prediction equations:

$$logit(P(Y \leq 1 )) = -3.4595 - 1.59665 * female -(-0.02726) * vocab - (-0.13533) * vocab*female $$
$$logit(P(Y \leq 2 )) = -1.1269 - 1.59665 * female -(-0.02726) * vocab - (-0.13533) * vocab*female $$

$$logit(P(Y \leq 3 )) = -0.6769 - 1.59665 * female -(-0.02726) * vocab - (-0.13533) * vocab*female $$

$$logit(P(Y \leq 4 )) = -0.0504 - 1.59665 * female -(-0.02726) * vocab - (-0.13533) * vocab*female $$

$$logit(P(Y \leq 5 )) = 1.3968 - 1.59665 * female -(-0.02726) * vocab - (-0.13533) * vocab*female $$

Now, that we have specified the prediction equations, we can move on to interpreting our coefficients. Given that we have an interaction term in our model, the interpretation will not be as straightforward. This is because the vocabulary score has a different effect on prayer depending on the gender. To begin with, we must specify the gender-specific prediction equations.

Male:

$$logit(P(Y \leq j )) = \alpha_{j} -(-0.02726) * vocab $$

```{r}
exp(-0.02726)
exp(confint(q3.mod2)[2,])
```

For males, the odds of being in a higher category (so higher prayer frequency) than a lower prayer category were estimated to decrease by a multiplicative factor of 0.9731082 for each one unit increase of vocab score. Likewise, vocabulary score has a negative association with the prayer frequency among males. We are 95% confident that this odds ratio falls between 0.8943838 and 1.0584712 .

Female: 

$$logit(P(Y \leq j )) = \alpha_{j}- 1.59665  -(-0.16259) * vocab$$

```{r}
exp(-0.16259)
exp(-0.02726 + confint(q3.mod2)[3,])
```

For females, the odds of being in a higher category (so higher prayer frequency) than a lower prayer category were estimated to decrease by a multiplicative factor of 0.8499396 for each one unit increase of vocab score. Likewise, vocabulary score has a negative association with the prayer frequency among females. We are 95% confident that this odds ratio falls between 0.7590772 0.9513869.

Even though the effect sizes were different, we can observe a negative association between vocab score and prayer among both genders according to our model.

As the interaction term's p-value was statistically significant (0.01877341), we are confident that gender plays a role in determining the effect of a unit increase in vocab score on the probability of being in a higher prayer category than in a lower one. Both odds ratios were between 0-1, and the odds ratio of vocab for females was lower than for males. This means that a one-unit increase in the vocab score has a more renounced effect for females than for males on decreasing the odds of being in a higher category than a lower category.


```{r}
diff.log.odds <- - 0.16259 - (-0.02726)
diff.log.odds
exp(diff.log.odds)
exp(-0.16259) / exp(-0.02726)
exp(confint(q3.mod2)[3,])
```

It is clear that the above calculations are correct for the varying effects of vocab according to gender. The summary output showed that the coefficient of the interaction term was -0.13533. This is the difference between the log odds of vocab under the male sub-model and the log odds of vocab under the female sub-model. Calculating the exponential of this value will give us the ratio of the odds ratio of vocab for females to the odds ratio of vocab for males. This means that, for each one unit increase of vocab score, the odds of being in a higher category (so higher prayer frequency) than in a lower category among females will decrease by a factor that is exp(-0.13533) = 0.8734276 (between 0.7800543 and 0.9776784 under 95% confidence) times the factor among males.


```{r}
library(reshape2)

transformed <- cbind(prayer, predict(q3.mod2, prayer, type = "probs"))
transformed <- melt(transformed, id.vars = c("female", "vocab"),
  variable.name = "Level", value.name="Probability")


females <- subset(transformed, female == 1)
males <- subset(transformed, female == 0)

females <- females[order(females$vocab, females$Probability),]
males <- males[order(males$vocab, males$Probability),]

par(mfrow=c(1,2))

matplot(females$vocab[females$Level == 1], females$Probability[females$Level == 1], type = "l", ylim = c(0,1), xlab = "Vocab",
     ylab = "Probability", main = "Females")
matlines(females$vocab[females$Level == 2], females$Probability[females$Level == 2], type = "l", col = "red")
matlines(females$vocab[females$Level == 3], females$Probability[females$Level == 3], type = "l", col = "blue")
matlines(females$vocab[females$Level == 4], females$Probability[females$Level == 4], type = "l", col = "green")
matlines(females$vocab[females$Level == 5], females$Probability[females$Level == 5], type = "l", col = "yellow")
matlines(females$vocab[females$Level == 6], females$Probability[females$Level == 6], type = "l", col = "orange")
legend("topright", lty = 1, col= c("black","red","blue","green","yellow","orange"), legend= 1:6)


matplot(males$vocab[males$Level == 1], males$Probability[males$Level == 1], type = "l", ylim = c(0,1), xlab = "Vocab",
     ylab = "Probability", main = "Males")
matlines(males$vocab[males$Level == 2], males$Probability[males$Level == 2], type = "l", col = "red")
matlines(males$vocab[males$Level == 3], males$Probability[males$Level == 3], type = "l", col = "blue")
matlines(males$vocab[males$Level == 4], males$Probability[males$Level == 4], type = "l", col = "green")
matlines(males$vocab[males$Level == 5], males$Probability[males$Level == 5], type = "l", col = "yellow")
matlines(males$vocab[males$Level == 6], males$Probability[males$Level == 6], type = "l", col = "orange")
legend("topleft", lty = 1, col= c("black","red","blue","green","yellow","orange"), legend= 1:6)

```


As you can see from above, our finding about the difference in the effect of vocab on each gender is visible in these plots. Even though the lines on the left and the right do not have a huge difference in steepness, the orange line (which indicates the probability of being in the highest-order prayer category) is much steeper for females than for males. This difference in the effect of vocab on the probability of being in the highest-order category clearly explains why the magnitude of vocab's effect on females was greater than that on males.
